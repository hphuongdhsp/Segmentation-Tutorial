experiment_name: "Pytorch Lightning with Huggingface"

data:
  dataset: Human Part Segmentation
  input_size: 512

model:
  type: transformers
  encoder_name: nvidia/segformer-b2-finetuned-ade-512-512
  size: 512
  in_channels: 3
  classes: 1

dataloader_type: "pytorch" # "kornia", "dali"
training:
  seed: 42
  device: "cuda:0"
  freeze_epochs: 1
  learning_rate: 0.001
  batch_size: 16
  workers: 4

testing:
  fold: 2
  phase: "test"
  batch_size: 16
  tta: True
  mixed_precision: False
  threshold: 0.39
  device: "cuda:0"

checkpoint_callback:
  type: pytorch_lightning.callbacks.ModelCheckpoint
  filename: segformer-b2
  monitor: valid_loss
  verbose: True
  save_top_k: 1
  save_last: True
  mode: min

trainer:
  type: pytorch_lightning.Trainer
  gpus: [0]
  max_epochs: 300
  benchmark: True
  precision: 16
  progress_bar_refresh_rate: 1
  gradient_clip_val: 5.0
  auto_lr_find: True
  weights_summary: "top"
  limit_train_batches: 1.0

debug: False

resume: False
